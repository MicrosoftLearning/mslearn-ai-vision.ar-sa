---
lab:
  title: اكتشاف العناصر في الصور باستخدام Custom Vision
  module: Module 9 - Developing Custom Vision Solutions
---

# اكتشاف العناصر في الصور باستخدام Custom Vision

في هذا التمرين، ستستخدم خدمة Custom Vision لتدريب *نموذج * الكشف عن العناصر الذي يمكنه اكتشاف وتحديد موقع ثلاث فئات من الفاكهة (التفاح والموز والبرتقال) في صورة.

## استنساخ المستودع لهذه الدورة التدريبية

إذا استنسخت بالفعل مستودع التعليمات البرمجية **mslearn-ai-vision** إلى البيئة التي تعمل فيها في هذا التمرين المعملي، فافتحه في تعليمة Visual Studio البرمجية؛ بخلاف ذلك، اتبع هذه الخطوات لاستنساخه الآن.

1. ابدأ تشغيل Visual Studio Code.
2. افتح لوحة (SHIFT+CTRL+P) وشغّل **Git: استنسخ الأمر ** لاستنساخ مستودع `https://github.com/MicrosoftLearning/mslearn-ai-vision` إلى مجلد محلي (لا يُهم أي مجلد).
3. عند استنساخ المستودع، افتح المجلد في تعليمة Visual Studio البرمجية.
4. انتظر حتى تثبيت ملفات إضافية لدعم مشروعات التعليمات البرمجية C# في المستودع.

    > **ملاحظة**: في حالة مطالبتك بإضافة الأصول المطلوبة للبناء وتصحيح الأخطاء، فحدد **ليس الآن**.

## إنشاء موارد الرؤية المخصصة

إذا كان لديك **بالفعل موارد Custom Vision** للتدريب والتنبؤ في اشتراك Azure الخاص بك، فيمكنك استخدامها في هذا التمرين. إذا لم يكن لديك ذلك، فاستخدم الإرشادات التالية لإنشائها.

1. في علامة تبويب جديدة لمستعرض، افتح مدخل Azure في `https://portal.azure.com`، ثم سجل الدخول باستخدام حساب Microsoft المقترن باشتراك Azure لديك.
2. اضغط على زر **&#65291، إنشاء مورد**وابحث عن*custom vision*، وأنشئ مورد** Custom Vision** باستخدام الإعدادات التالية:
    - **إنشاء خيارات**: كلاهما
    - **Subscription**: *اشتراكك في Azure*
    - **مجموعة الموارد**: *اختر أو أنشئ مجموعة موارد (إذا كنت تستخدم اشتراكًا مقيدًا، فقد لا يكون لديك إذن لإنشاء مجموعة موارد جديدة - استخدم المجموعة المتوفرة)*
    - **المنطقة**: *اختر أي منطقة متوفرة*
    - **الاسم**: *أدخل اسماً فريداً*
    - **مستوى أسعار التدريب:** F0
    - **مستوى أسعار التنبؤ**: F0

    > **ملاحظة**: إذا كانت لديك خدمة رؤية معدلة F0 في اشتراكك مسبقًا، فاختر **S0** لأجل هذا.

3. انتظر حتى يتم إنشاء الموارد، ثم اعرض تفاصيل التوزيع ولاحظ أنه يتم توفير موردين لـ Custom Vision؛ مورد للتدريب، ومورد آخر للتنبؤ (الذي يتجلى عن طريق لاحقة **-التنبؤ** ). يمكنك عرض هذا من خلال الانتقال إلى مجموعة الموارد حيث قمت بإنشائها.

> **مهم**: لكل مورد * نقطة نهاية *و*مفاتيح*خاصة به، والتي تستخدم لإدارة الوصول من التعليمات البرمجية الخاصة بك. لتدريب نموذج تصنيف الصور، يجب أن تستخدم التعليمات البرمجية لديك مورد * التدريب* (بنقطة النهاية والمفتاح الخاص بها)؛ ولاستخدام النموذج المدرب للتنبؤ بفئات الصور، يجب أن تستخدم التعليمات البرمجية لديك مورد* التنبؤ* (باستخدام نقطة النهاية والمفتاح الخاص بها).

## إنشاء مشروع Custom Vision

لتدريب نموذج اكتشاف العنصر، تحتاج إلى إنشاء مشروع رؤية مخصصة بناءً على مورد التدريب الخاص بك. للقيام بذلك، ستستخدم مدخل Custom Vision.

1. في علامة تبويب مستعرض جديدة، افتح مدخل "Custom Vision" في `https://customvision.ai`، ثم سجل الدخول باستخدام حساب Microsoft المقترن باشتراك Azure.
2. إنشاء مشروع جديد بالإعدادات التالية:
    - **الاسم**: كشف الفاكهة
    - **الوصف**: الكشف عن العناصر للفاكهة.
    - **المورد**: * مورد Custom Vision الذي أنشأته مسبقًا*
    - **أنواع المشروع**: الكشف عن الكائنات
    - **النطاقات**: عام
3. انتظر المشروع إلى إنشاء وفتح في المستعرض.

## إضافة الصور ووضع علامة لها

لتدريب نموذج اكتشاف الكائن، تحتاج إلى تحميل الصور التي تحتوي على الفئات التي تريد أن يحددها النموذج، وتمييزها للإشارة إلى المربعات المحيطة لكل مثيل كائن.

1. في تعليمة Visual Studio البرمجية، اطلع على صور التدريب في مجلد** 03-object-detection/training-images** حيث قمت باستنساخ المستودع. يحتوي هذا المجلد على صور للفاكهة.
2. في منصة الرؤية المعدلة في مشروع الكشف عن الأشياء، اختر **إضافة الصور** وحمل جميع الصور من الملف المستخرج.
3. بعد تحميل الصور، حدد أول صورة تفتحها.
4. ضع الماوس فوق أي كائن في الصورة حتى يتم عرض المنطقة المكتشفة تلقائيًا مثل الصورة أدناه. ثم حدد الكائن، وإذا لزم الأمر، قم بتغيير حجم المنطقة المحيطة به.

![المنطقة الافتراضية لكائن](../media/object-region.jpg)

بدلاً من ذلك، يمكنك ببساطة السحب حول الكائن لإنشاء منطقة.

5. عندما تحيط المنطقة بالكائن، أضف علامة جديدة بنوع الكائن المناسب (*التفاح* أو *الموز* أو *البرتقال*) كما هو موضح هنا:

![كائن معلم في صورة](../media/object-tag.jpg)

6. حدد كل كائن آخر في الصورة وقم بتمييزه، وقم بتغيير حجم المناطق وإضافة علامات جديدة حسب الحاجة.

![كائنان معلمان في صورة](../media/object-tags.jpg)

7. استخدم الرابط **>** الموجود على اليمين للانتقال إلى الصورة التالية، ووضع علامة على كائناتها. ثم استمر في العمل من خلال مجموعة الصور بأكملها، ووضع علامات على كل تفاحة وموز وبرتقال.

8. عند الانتهاء من وضع علامات على الصورة الأخيرة، أغلق محرر **Image Detail** وفي صفحة **Training Images** ضمن **Tags**، حدد **Tagged** لمشاهدة جميع الصور ذات العلامات:

![الصور ذات العلامات في مشروع](../media/tagged-images.jpg)

## استخدام واجهة برمجة تطبيقات التدريب لتحميل الصور

يمكنك استخدام الأداة الرسومية في مدخل Custom Vision لوضع علامة على صورك، ولكن العديد من فرق التطوير الذكاء الاصطناعي تستخدم أدوات أخرى تنشئ ملفات تحتوي على معلومات حول العلامات ومناطق العناصر في الصور. في سيناريوهات مثل هذه، يمكنك استخدام واجهة برمجة تطبيقات تدريب Custom Vision لتحميل الصور ذات العلامات إلى المشروع.

> **ملاحظة**: في هذا التمرين، يمكنك اختيار استخدام واجهة برمجة التطبيقات إما **من C#** أو **Python** SDK. في الخطوات الواردة أدناه، نفذ الإجراءات المناسبة للغتك المفضلة.

1. انقر فوق أيقونة *الإعدادات* (#9881;) في الجزء العلوي الأيمن من صفحة**صور التدريب** في مدخل Custom Vision لعرض إعدادات المشروع.
2. ضمن **عام** (على اليسار)، لاحظ **معرف المشروع** لذي يعرف هذا المشروع بشكل فريد.
3. على اليمين، ضمن **الموارد** لاحظ أنه يتم عرض المفتاح ونقطة النهاية. هذه هي تفاصيل مورد * التدريب* (يمكنك أيضًا الحصول على هذه المعلومات عن طريق عرض المورد في مدخل Microsoft Azure).
4. في تعليمة Visual Studio البرمجية، ضمن مجلد**03-object-detection**، قم بتوسيع مجلد** C-Sharp**أو **Python**استنادًا إلى تفضيلات اللغة.
5. انقر بزر الماوس الأيمن فوق مجلد **train-detector** وافتح وحدة طرفية متكاملة. ثم قم بتثبيت حزمة تدريب Custom Vision عن طريق تشغيل الأمر المناسب لتفضيل اللغة لديك:

**C#**

```
dotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Training --version 2.0.0
```

**Python**

```
pip install azure-cognitiveservices-vision-customvision==3.1.0
```

6. اعرض محتويات مجلد **train-detector**، ولاحظ أنه يحتوي على ملف لإعدادات التكوين:
    - **C#**: appsettings.json
    - **Python**: .env

    افتح ملف التكوين وقم بتحديث قيم التكوين التي يحتوي عليها لتعكس نقطة النهاية والمفتاح لمورد تدريب* Custom Vision *لديك ومعرّف المشروع لمشروع الكشف عن العناصر الذي قمت بإنشائه مسبقًا. احفظ تغييراتك.

7. في مجلد ** train-detector**، افتح **tagged-images.json** وافحص ملف JSON الذي يحتوي عليه. يحدد JSON قائمة بالصور، كل منها تحتوي على منطقة واحدة أو أكثر ذات علامات. تتضمن كل منطقة ذات علامة اسم علامة، والإحداثيات العلوية واليسرى وأبعاد العرض والارتفاع لمربع الإحاطة الذي يحتوي على الكائن ذي علامة.

    > **ملاحظة**: تشير الإحداثيات والأبعاد في هذا الملف إلى نقاط نسبية على الصورة. على سبيل المثال، تشير قيمة* الارتفاع* 0.7 إلى مربع يمثل 70% من ارتفاع الصورة. تنشئ بعض أدوات وضع العلامات تنسيقات أخرى من الملفات حيث تمثل قيم الإحداثيات والأبعاد وحدات البكسل أو البوصة أو وحدات القياس الأخرى.

8. لاحظ أن مجلد ** train-detector** يحتوي على مجلد فرعي يتم فيه تخزين ملفات الصور المشار إليها في ملف JSON.


9. لاحظ أن مجلد **train-detector** يحتوي على ملف تعليمات برمجية لتطبيق العميل:

    - **C#**: Program.cs
    - **Python**: train-detector.py

    افتح ملف التعليمات البرمجية وراجع التعليمات البرمجية التي يحتوي عليها، مع ملاحظة التفاصيل التالية:
    - يتم استيراد مساحات الأسماء من الحزمة التي قمت بتثبيتها
    - تسترد الدالة ** Main** إعدادات التكوين، وتستخدم المفتاح ونقطة النهاية لإنشاء **CustomVisionTrainingClient** مصدق عليه، والذي يتم استخدامه بعد ذلك مع معرف المشروع لإنشاء مرجع** مشروع** إلى مشروعك.
    - تستخرج الدالة ** Upload_Images** معلومات المنطقة ذات العلامات من ملف JSON وتستخدمها لإنشاء مجموعة من الصور مع المناطق، والتي تقوم بتحميلها بعد ذلك إلى المشروع.
10. أعد الوحدة الطرفية المتكاملة للمجلد **train-detector**، وأدخل الأمر التالي لتشغيل البرنامج:
    
**C#**

```
dotnet run
```

**Python**

```
python train-detector.py
```
    
11. انتظر حتى ينتهي البرنامج. ثم ارجع إلى المستعرض الخاص بك واعرض صفحة **صور التدريب** لمشروعك في مدخل Custom Vision (قم بتحديث المتصفح إذا لزم الأمر).
12. تحقق من إضافة بعض الصور ذات العلامات الجديدة إلى المشروع.

## تدريب واختبار نموذج

الآن بعد أن قمت بتمييز الصور في مشروعك، فأنت جاهز لتدريب نموذج.

1. في مشروع Custom Vision، انقر فوق **Train** لتدريب نموذج اكتشاف كائن باستخدام الصور ذات العلامات. حدد خيار **Quick Training**
2. انتظر حتى يكتمل التدريب (قد يستغرق عشر دقائق أو نحو ذلك)، ثم قم بمراجعة مقاييس أداء *الدقة* و*الاستدعاء* و*mAP*، والتي تقيس دقة التنبؤ لنموذج التصنيف، ويجب أن تكون جميعها عالية.
3. في أعلى يمين الصفحة، انقر فوق **Quick Test**، ثم في المربع **Image URL** أدخل `https://aka.ms/apple-orange` واعرض التوقع الذي تم إنشاؤه. ثم أغلق نافذة **Quick Test**.

## نشر نموذج الكشف عن الكائنات

أنت الآن جاهز لنشر نموذجك المدرّب بحيث يمكن استخدامه من تطبيق عميل.

1. في مدخل Custom Vision، في صفحة **الأداء**، انقر فوق **&#128504; نشر** لنشر النموذج المُدرب بالإعدادات التالية:
    - **اسم النموذج**: fruit-detector
    - **مورد التنبؤ**: *مورد **التنبؤ** الذي أنشأته سابقًا والذي ينتهي بـ "-Prediction" (<u>ليس هو</u> مورد التدريب)*.
2. في الجزء العلوي الأيسر من صفحة **إعدادات المشروع**، انقر فوق أيقونة *معرض المشاريع* (&#128065;) للعودة إلى الصفحة الرئيسية لمدخل Custom Vision، حيث يتم إدراج مشروعك الآن.
3. في الصفحة الرئيسية لمدخل Custom Vision، في أعلى اليمين، انقر فوق أيقونة *الإعدادات * (&#9881;) لعرض إعدادات خدمة Custom Vision الخاصة بك. ثم، ضمن **الموارد**، ابحث عن مورد * التنبؤ *الذي ينتهي بـ "-Prediction" (<u>وليس</u> مورد التدريب) لتحديد قيم ** المفتاح **** ونقطة النهاية الخاصة به **(يمكنك أيضًا الحصول على هذه المعلومات عن طريق عرض المورد في مدخل Microsoft Azure).

## استخدام مصنف الصور من تطبيق عميل

الآن بعد أن قمت بنشر نموذج تصنيف الصور، يمكنك استخدامه من تطبيق عميل. مرة أخرى، يمكنك اختيار استخدام **C#** أو **Python**.

1. في تعليمة Visual Studio البرمجية استعرض للوصول إلى مجلد**03-object-detection** وفي المجلد للغة المفضلة لديك (**C-Sharp** أو **Python**)، قم بتوسيع مجلد**test-detector**.
2. انقر بزر الماوس الأيمن فوق مجلد **test-detector** وافتح وحدة طرفية متكاملة. ثم أدخل الأمر التالي الخاص بـ SDK لتثبيت حزمة تنبؤ Custom Vision:

**C#**

```
dotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Prediction --version 2.0.0
```

**Python**

```
pip install azure-cognitiveservices-vision-customvision==3.1.0
```

> **ملاحظة**: تتضمن حزمة Python SDK كلا من حزم التدريب والتنبؤ، وقد تكون مثبتة بالفعل.

3. افتح ملف التكوين لتطبيق العميل الخاص بك (*appsettings.json* لـ C# أو *.env* لـ Python) وقم بتحديث قيم التكوين التي يحتوي عليها لتعكس نقطة النهاية والمفتاح لمورد توقع* Custom Vision ومعرف* المشروع لمشروع الكشف عن العناصر واسم النموذج المنشور (الذي يجب أن يكون *fruit-detector*). احفظ تغييراتك.
4. افتح ملف التعليمات البرمجية لتطبيق العميل الخاص بك (*Program.cs* لـ C#، *test-detector.py* لـ Python) وراجع التعليمات البرمجية التي يحتوي عليها، مع ملاحظة التفاصيل التالية:
    - يتم استيراد مساحات الأسماء من الحزمة التي قمت بتثبيتها
    - تسترد الدالة ** Main** إعدادات التكوين، وتستخدم المفتاح ونقطة النهاية لإنشاء **CustomVisionPredictionClient** مصدّق عليه.
    - يتم استخدام عنصر عميل التنبؤ للحصول على تنبؤات الكشف عن العناصر للصورة **produce.jpg**، مع تحديد معرف المشروع واسم النموذج في الطلب. ثم يتم رسم المناطق ذات العلامات المتوقعة على الصورة، وتُحفظ النتيجة على أنها **output.jpg**.
5. أعد الوحدة الطرفية المتكاملة للمجلد **test-detector**، وأدخل الأمر التالي لتشغيل البرنامج:

**C#**

```
dotnet run
```

**Python**

```
python test-detector.py
```

6. بعد اكتمال البرنامج، اعرض ملف **output.jpg** الناتج للاطلاع على العناصر المكتشفة في الصورة.

## مزيد من المعلومات

لمزيد من المعلومات حول الكشف عن العناصر باستخدام خدمة Custom Vision، راجع وثائق [Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/).
