---
lab:
  title: كشف العانصر في الصور باستخدام الرؤية المخصصة في الذكاء الاصطناعي في Azure
---

# كشف العانصر في الصور باستخدام الرؤية المخصصة في الذكاء الاصطناعي في Azure

في هذا التمرين، ستستخدم خدمة Custom Vision لتدريب *نموذج * الكشف عن العناصر الذي يمكنه اكتشاف وتحديد موقع ثلاث فئات من الفاكهة (التفاح والموز والبرتقال) في صورة.

## إنشاء موارد الرؤية المخصصة

إذا كان لديك بالفعل موارد **رؤية مخصصة** للتدريب والتوقع في اشتراك Azure الخاص بك، فيمكنك استخدامها في هذا التدريب. إذا لم يكن لديك ذلك، فاستخدم الإرشادات التالية لإنشائها.

> **ملاحظة**: إذا كنت تستخدم حسابًا متعدد الخدمات، فسيكون المفتاح ونقطة النهاية متشابهين لكل من التدريب والتوقع.

1. في علامة تبويب جديدة لمستعرض، افتح مدخل Azure في `https://portal.azure.com`، ثم سجل الدخول باستخدام حساب Microsoft المقترن باشتراك Azure لديك.
1. اضغط على زر **&#65291، إنشاء مورد**وابحث عن*custom vision*، وأنشئ مورد** Custom Vision** باستخدام الإعدادات التالية:
    - **إنشاء خيارات**: كلاهما
    - **Subscription**: *اشتراكك في Azure*
    - **مجموعة الموارد**: *اختر أو أنشئ مجموعة موارد (إذا كنت تستخدم اشتراكًا مقيدًا، فقد لا يكون لديك إذن لإنشاء مجموعة موارد جديدة - استخدم المجموعة المتوفرة)*
    - **المنطقة**: *اختر أي منطقة متوفرة*
    - **الاسم**: *أدخل اسماً فريداً*
    - **مستوى أسعار التدريب:** F0
    - **مستوى أسعار التنبؤ**: F0

    > **ملاحظة**: إذا كانت لديك خدمة رؤية معدلة F0 في اشتراكك مسبقًا، فاختر **S0** لأجل هذا.

1. انتظر حتى يتم إنشاء الموارد، ثم اعرض تفاصيل التوزيع ولاحظ أنه يتم توفير موردين لـ Custom Vision؛ مورد للتدريب، ومورد آخر للتنبؤ (الذي يتجلى عن طريق لاحقة **-التنبؤ** ). يمكنك عرض هذا من خلال الانتقال إلى مجموعة الموارد حيث قمت بإنشائها.

> **مهم**: لكل مورد * نقطة نهاية *و*مفاتيح*خاصة به، والتي تستخدم لإدارة الوصول من التعليمات البرمجية الخاصة بك. لتدريب نموذج تصنيف الصور، يجب أن تستخدم التعليمات البرمجية لديك مورد * التدريب* (بنقطة النهاية والمفتاح الخاص بها)؛ ولاستخدام النموذج المدرب للتنبؤ بفئات الصور، يجب أن تستخدم التعليمات البرمجية لديك مورد* التنبؤ* (باستخدام نقطة النهاية والمفتاح الخاص بها).

## استنساخ المستودع لهذه الدورة التدريبية

ستقوم بتطوير التعليمات البرمجية الخاصة بك باستخدام Cloud Shell من بوابة Azure. تم توفير ملفات التعليمات البرمجية لتطبيقك في GitHub repo.

> **تلميح**: إذا كنت قد نسخت المستودع **mslearn-ai-vision** مؤخرًا بالفعل، فيمكنك تخطي هذه المهمة. وإلا فاتبع هذه الخطوات لاستنساخه إلى بيئة تطويرك.

1. في بوابة Azure، استخدم الزر **[\>_]** على يمين شريط البحث أعلى الصفحة لإنشاء Cloud Shell جديد في بوابة Azure، وتحديد بيئة ***PowerShell***. يوفّر Cloud Shell واجهة سطر أوامر في جزء أسفل بوابة Azure.

    > **ملاحظة**: إذا كنت قد أنشأت مسبقًا Cloud Shell يستخدم بيئة *معالج Bash*، فبدّل إلى ***PowerShell***.

1. في شريط أدوات Cloud Shell، في قائمة **الإعدادات**، حدد **الانتقال إلى الإصدار الكلاسيكي** (هذا مطلوب لاستخدام محرر التعليمات البرمجية).

    > **تلميح**: عند لصق الأوامر في CloudShell، قد يشغل الإخراج مساحة كبيرة من ذاكرة التخزين المؤقت للشاشة. يمكنك مسح الشاشة عن طريق إدخال الأمر `cls` لتسهيل التركيز على كل مهمة.

1. في جزء PowerShell، أدخل الأوامر التالية لاستنساخ مستودع GitHub لهذا التمرين:

    ```
    rm -r mslearn-ai-vision -f
    git clone https://github.com/microsoftlearning/mslearn-ai-vision mslearn-ai-vision
    ```

1. بعد استنساخ مخزن بيانات خاصة، انتقل إلى المجلد الذي يحتوي على ملفات التعليمات البرمجية لتطبيق الدردشة:  

    ```
   cd mslearn-ai-vision/Labfiles/03-object-detection
    ```

## إنشاء مشروع Custom Vision

لتدريب نموذج اكتشاف العنصر، تحتاج إلى إنشاء مشروع رؤية مخصصة بناءً على مورد التدريب الخاص بك. للقيام بذلك، ستستخدم مدخل Custom Vision.

1. في علامة تبويب مستعرض جديدة، افتح مدخل "Custom Vision" في `https://customvision.ai`، ثم سجل الدخول باستخدام حساب Microsoft المقترن باشتراك Azure.
1. إنشاء مشروع جديد بالإعدادات التالية:
    - **الاسم**: كشف الفاكهة
    - **الوصف**: الكشف عن العناصر للفاكهة.
    - **المورد**: * مورد Custom Vision الذي أنشأته مسبقًا*
    - **أنواع المشروع**: الكشف عن الكائنات
    - **النطاقات**: عام
1. انتظر المشروع إلى إنشاء وفتح في المستعرض.

## إضافة الصور ووضع علامة لها

لتدريب نموذج اكتشاف الكائن، تحتاج إلى تحميل الصور التي تحتوي على الفئات التي تريد أن يحددها النموذج، وتمييزها للإشارة إلى المربعات المحيطة لكل مثيل كائن.

1. نزِّل صور التدريب من `https://github.com/MicrosoftLearning/mslearn-ai-vision/raw/main/Labfiles/03-object-detection/training-images.zip` واستخرج المجلد المضغوط لعرض محتوياته. يحتوي هذا المجلد على صور للفاكهة.
1. في منصة الرؤية المعدلة في مشروع الكشف عن الأشياء، اختر **إضافة الصور** وحمل جميع الصور من الملف المستخرج.
1. بعد تحميل الصور، حدد أول صورة تفتحها.
1. ضع الماوس فوق أي كائن في الصورة حتى يتم عرض المنطقة المكتشفة تلقائيًا مثل الصورة أدناه. ثم حدد الكائن، وإذا لزم الأمر، قم بتغيير حجم المنطقة المحيطة به.

    ![المنطقة الافتراضية لكائن](../media/object-region.jpg)

    بدلاً من ذلك، يمكنك ببساطة السحب حول الكائن لإنشاء منطقة.

1. عندما تحيط المنطقة بالكائن، أضف علامة جديدة بنوع الكائن المناسب (*التفاح* أو *الموز* أو *البرتقال*) كما هو موضح هنا:

    ![كائن معلم في صورة](../media/object-tag.jpg)

1. حدد كل كائن آخر في الصورة وقم بتمييزه، وقم بتغيير حجم المناطق وإضافة علامات جديدة حسب الحاجة.

    ![كائنان معلمان في صورة](../media/object-tags.jpg)

1. استخدم الرابط **>** الموجود على اليمين للانتقال إلى الصورة التالية، ووضع علامة على كائناتها. ثم استمر في العمل من خلال مجموعة الصور بأكملها، ووضع علامات على كل تفاحة وموز وبرتقال.

1. عند الانتهاء من وضع علامات على الصورة الأخيرة، أغلق محرر ** تفاصيل الصورة**. في صفحة **تدريب الصور**، ضمن **العلامات**، حدد **الصور ذات العلامات** لمشاهدة جميع الصور ذات العلامات:

![الصور ذات العلامات في مشروع](../media/tagged-images.jpg)

## استخدام واجهة برمجة تطبيقات التدريب لتحميل الصور

يمكنك استخدام UI في بوابة الرؤية المخصصة لوضع علامة على صورك، ولكن العديد من فرق التطوير الذكاء الاصطناعي تستخدم أدوات أخرى تنشئ ملفات تحتوي على معلومات حول العلامات ومناطق العناصر في الصور. في سيناريوهات مثل هذه، يمكنك استخدام واجهة برمجة تطبيقات تدريب Custom Vision لتحميل الصور ذات العلامات إلى المشروع.

> **ملاحظة**: في هذا التمرين، يمكنك اختيار استخدام واجهة برمجة التطبيقات إما **من C#** أو **Python** SDK. في الخطوات الواردة أدناه، نفذ الإجراءات المناسبة للغتك المفضلة.

1. انقر فوق أيقونة *الإعدادات* (#9881;) في الجزء العلوي الأيمن من صفحة**صور التدريب** في مدخل Custom Vision لعرض إعدادات المشروع.
1. ضمن **عام** (على اليسار)، لاحظ **معرف المشروع** لذي يعرف هذا المشروع بشكل فريد.
1. على اليمين، ضمن **الموارد** لاحظ أنه يتم عرض المفتاح ونقطة النهاية. هذه هي تفاصيل مورد * التدريب* (يمكنك أيضًا الحصول على هذه المعلومات عن طريق عرض المورد في مدخل Microsoft Azure).
1. مرة أخرى في مدخل Microsoft Azure، شغِّل الأمر `cd C-Sharp/train-detector` أو `cd Python/train-detector` وفقًا لتفضيل اللغة لديك.
1. ثبِّت حزمة تدريب Custom Vision بتشغيل الأمر المناسب لتفضيل اللغة لديك:

    **C#**

    ```
   dotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Training --version 2.0.0
    ```

    **Python**

    ```
   pip install azure-cognitiveservices-vision-customvision==3.1.1
    ```

1. باستخدام الأمر `ls`، يمكنك عرض محتويات المجلد **train-detector**. لاحظ أنه يحتوي على ملف لإعدادات التكوين:

    - **C#**: appsettings.json
    - **Python**: .env

1. أدخل الأمر التالي لتحرير ملف التكوين الذي تم توفيره:

    **C#**

    ```
   code appsettings.json
    ```

    **Python**

    ```
   code .env
    ```

    يتم فتح الملف في محرر التعليمات البرمجية.

1. في ملف التعليمات البرمجية، حدِّث قيم التكوين التي يحتوي عليها الملف لتعكس **نقطة النهاية** ومفتاح **مصادقة** لمورد تمرين *Custom Vision* الخاص بك ومعرّف المشروع لمشروع الكشف عن العناصر الذي أنشأته مسبقًا.
1. بعد استبدال العناصر النائبة، استخدم الأمر **CTRL+S** أو **Right-click > Save** لحفظ التغييرات ثم استخدم الأمر **CTRL+Q** أو **Right-click > Quit** لإغلاق محرر التعليمات البرمجية مع إبقاء سطر أوامر Cloud Shell مفتوحًا.
1. شغِّل `code tagged-images.json` لفتح الملف واستعراض بيانات JSON التي يتضمنها. يحدد JSON قائمة بالصور، كل منها تحتوي على منطقة واحدة أو أكثر ذات علامات. تتضمن كل منطقة ذات علامة اسم علامة، والإحداثيات العلوية واليسرى وأبعاد العرض والارتفاع لمربع الإحاطة الذي يحتوي على الكائن ذي علامة.

    > **ملاحظة**: تشير الإحداثيات والأبعاد في هذا الملف إلى نقاط نسبية على الصورة. على سبيل المثال، تشير قيمة* الارتفاع* 0.7 إلى مربع يمثل 70% من ارتفاع الصورة. تنشئ بعض أدوات وضع العلامات تنسيقات أخرى من الملفات حيث تمثل قيم الإحداثيات والأبعاد وحدات البكسل أو البوصة أو وحدات القياس الأخرى.

1. لاحظ أن مجلد ** train-detector** يحتوي على مجلد فرعي يتم فيه تخزين ملفات الصور المشار إليها في ملف JSON.

1. لاحظ أن مجلد **train-detector** يحتوي على ملف تعليمات برمجية لتطبيق العميل:

    - **C#**: Program.cs
    - **Python**: train-detector.py

    افتح ملف التعليمات البرمجية وراجع التعليمات البرمجية التي يحتوي عليها، مع ملاحظة التفاصيل التالية:
    - يتم استيراد مساحات الأسماء من الحزمة التي قمت بتثبيتها
    - تسترد الدالة ** Main** إعدادات التكوين، وتستخدم المفتاح ونقطة النهاية لإنشاء **CustomVisionTrainingClient** مصدق عليه، والذي يتم استخدامه بعد ذلك مع معرف المشروع لإنشاء مرجع** مشروع** إلى مشروعك.
    - تستخرج الدالة ** Upload_Images** معلومات المنطقة ذات العلامات من ملف JSON وتستخدمها لإنشاء مجموعة من الصور مع المناطق، والتي تقوم بتحميلها بعد ذلك إلى المشروع.

1. أدخِل الأمر التالي لتشغيل البرنامج:
    
    **C#**
    
    ```
   dotnet run
    ```
    
    **Python**
    
    ```
   python train-detector.py
    ```
    
1. انتظر حتى ينتهي البرنامج. ثم ارجع إلى المستعرض الخاص بك واعرض صفحة **صور التدريب** لمشروعك في مدخل Custom Vision (قم بتحديث المتصفح إذا لزم الأمر).
1. تحقق من إضافة بعض الصور ذات العلامات الجديدة إلى المشروع.

## تدريب واختبار نموذج

الآن بعد أن قمت بتمييز الصور في مشروعك، فأنت جاهز لتدريب نموذج.

1. في مشروع Custom Vision، انقر فوق **Train** لتدريب نموذج اكتشاف كائن باستخدام الصور ذات العلامات. حدد خيار **Quick Training**
1. انتظر حتى يكتمل التدريب (قد يستغرق عشر دقائق أو نحو ذلك)، ثم قم بمراجعة مقاييس أداء *الدقة* و*الاستدعاء* و*mAP*، والتي تقيس دقة التنبؤ لنموذج التصنيف، ويجب أن تكون جميعها عالية.
1. في أعلى يمين الصفحة، انقر فوق **Quick Test**، ثم في المربع **Image URL** أدخل `https://aka.ms/apple-orange` واعرض التوقع الذي تم إنشاؤه. ثم أغلق نافذة **Quick Test**.

## نشر نموذج الكشف عن الكائنات

أنت الآن جاهز لنشر نموذجك المدرّب بحيث يمكن استخدامه من تطبيق عميل.

1. في مدخل Custom Vision، في صفحة **الأداء**، انقر فوق **&#128504; نشر** لنشر النموذج المُدرب بالإعدادات التالية:
    - **اسم النموذج**: fruit-detector
    - **مورد التنبؤ**: *مورد **التنبؤ** الذي أنشأته سابقًا والذي ينتهي بـ "-Prediction" (<u>ليس هو</u> مورد التدريب)*.
1. في الجزء العلوي الأيسر من صفحة **إعدادات المشروع**، انقر فوق أيقونة *معرض المشاريع* (&#128065;) للعودة إلى الصفحة الرئيسية لمدخل Custom Vision، حيث يتم إدراج مشروعك الآن.
1. في الصفحة الرئيسية لمدخل Custom Vision، في أعلى اليمين، انقر فوق أيقونة *الإعدادات * (&#9881;) لعرض إعدادات خدمة Custom Vision الخاصة بك. ثم، ضمن **الموارد**، ابحث عن مورد * التنبؤ *الذي ينتهي بـ "-Prediction" (<u>وليس</u> مورد التدريب) لتحديد قيم ** المفتاح **** ونقطة النهاية الخاصة به **(يمكنك أيضًا الحصول على هذه المعلومات عن طريق عرض المورد في مدخل Microsoft Azure).

## استخدام مصنف الصور من تطبيق عميل

الآن بعد أن قمت بنشر نموذج تصنيف الصور، يمكنك استخدامه من تطبيق عميل. مرة أخرى، يمكنك اختيار استخدام **C#** أو **Python**.

1. في مدخل Microsoft Azure، انتقل إلى مجلد **test-detector** باستخدام الأمر `cd ../test-detector`.
1. أدخِل الأمر التالي الخاص بعدة تطوير البرامج (SDK) لتثبيت حزمة التنبؤ الخاصة بـ Custom Vision:

    **C#**

    ```
   dotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Prediction --version 2.0.0
    ```

    **Python**

    ```
   pip install azure-cognitiveservices-vision-customvision==3.1.1
    ```

> **ملاحظة**: تتضمن حزمة Python SDK كلا من حزم التدريب والتنبؤ، وقد تكون مثبتة بالفعل.

1. افتح ملف التكوين لتطبيق العميل الخاص بك (*appsettings.json* لـ C# أو *.env* لـ Python) وقم بتحديث قيم التكوين التي يحتوي عليها لتعكس نقطة النهاية والمفتاح لمورد توقع* Custom Vision ومعرف* المشروع لمشروع الكشف عن العناصر واسم النموذج المنشور (الذي يجب أن يكون *fruit-detector*). احفظ التغييرات التي أجريتها ثم أغلق الملف.
1. افتح ملف التعليمات البرمجية لتطبيق العميل الخاص بك (*Program.cs* لـ C#، *test-detector.py* لـ Python) وراجع التعليمات البرمجية التي يحتوي عليها، مع ملاحظة التفاصيل التالية:
    - يتم استيراد مساحات الأسماء من الحزمة التي قمت بتثبيتها
    - تسترد الدالة ** Main** إعدادات التكوين، وتستخدم المفتاح ونقطة النهاية لإنشاء **CustomVisionPredictionClient** مصدّق عليه.
    - يتم استخدام عنصر عميل التنبؤ للحصول على تنبؤات الكشف عن العناصر للصورة **produce.jpg**، مع تحديد معرف المشروع واسم النموذج في الطلب. ثم يتم رسم المناطق ذات العلامات المتوقعة على الصورة، وتُحفظ النتيجة على أنها **output.jpg**.
1. أغلِق محرر التعليمات البرمجية وأدخِل الأمر التالي لتشغيل البرنامج:

    **C#**

    ```
   dotnet run
    ```

    **Python**

    ```
   python test-detector.py
    ```

1. بعد اكتمال تشغيل البرنامج، في شريط أدوات cloud shell، حدد **تحميل/تنزيل الملفات** ثم **تنزيل**. في مربع الحوار الجديد، أدخِل مسار الملف التالي وحدد **تنزيل**:

    **C#**
   
    ```
   mslearn-ai-vision/Labfiles/03-object-detection/C-Sharp/test-detector/output.jpg
    ```

    **Python**
   
    ```
   mslearn-ai-vision/Labfiles/03-object-detection/Python/test-detector/output.jpg
    ```

1. اعرض ملف **output.jpg** الناتج لرؤية الكائنات المكتشفة في الصورة.

## تنظيف الموارد

إذا كنت لا تستخدم موارد Azure التي أنشأتها في هذا المختبر لوحدات التدريب الأخرى، فيمكنك حذفها لتجنب تكبد المزيد من الرسوم.

1. افتح مدخل Azure في `https://portal.azure.com`، وفي شريط البحث العلوي، ابحث عن الموارد التي أنشأتها في هذا المختبر.

1. في صفحة المورد، حدد **حذف** واتبع الإرشادات لحذف المورد. بدلاً من ذلك، يمكنك حذف مجموعة الموارد بأكملها لتنظيف جميع الموارد في الوقت نفسه.
   
## مزيد من المعلومات

لمزيد من المعلومات حول الكشف عن العناصر باستخدام خدمة Custom Vision، راجع وثائق [Custom Vision](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/).
